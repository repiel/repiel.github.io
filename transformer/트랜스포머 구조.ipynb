{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a39b05",
   "metadata": {},
   "source": [
    "# 트랜스포머와 Seq2Seq와 차이점 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94525708",
   "metadata": {},
   "source": [
    "## Seq2Seq\n",
    "- 문단 하나 하나가 하나의 LSTM에 담겨 h1에 담긴다.\n",
    "- 그리고 이것이 문맥 벡터에 담겨 LSTM으로 된 후 변환이 된다.\n",
    "\n",
    "### 단점\n",
    "- 문맥 벡터가 encoder의 모든 시퀀스 정보를 포함하고 있기 때문에, decoding 시 개별 토큰과의 관계 파악이 어려움\n",
    "- 문단이 길어지는 경우 RNN의 고질적인 문제인 기울기 소실의 위험이 있음\n",
    "- 무척 복잡하다.\n",
    "\n",
    "### 장점\n",
    "- 각 토큰이 Sequential하게 RNN cell에 입력되므로 입력 시퀀스들의 순서(위치)정보가 보존된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f800cd",
   "metadata": {},
   "source": [
    "## 트랜스포머\n",
    "### 단점\n",
    "- 시퀀스(토큰)를 한번에 다 입력하는 형태이므로, 순서(위치)정보가 보존되지 않음.\n",
    "\n",
    "### 장점\n",
    "- 긴 길이의 문장이 입력되어도 일반화가 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887b5c2",
   "metadata": {},
   "source": [
    "# 트랜스포머의 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ad4103",
   "metadata": {},
   "source": [
    "### 트랜스포머의 특징\n",
    "- 크게 인코더와 디코더로 나누어져있다. \n",
    "- Q(쿼리), K(키), V(값, 밸류)가 중요한 특징이다.\n",
    "- 각 토큰의 위치마다 유일한 값을 지녀야 한다.\n",
    "- 토큰 간 차이가 일정한 의미를 지녀야 한다.(멀수록 큰 값이 되어야 한다)\n",
    "- 인코더에서 도출한 값과 디코더에서 도출한 값의 차원 및 길이는 같아야 한다.\n",
    "- 디코더에서 도출된 값 후에 Linear과 Softmax를 이용해 최종 결과를 도출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2d1fa5",
   "metadata": {},
   "source": [
    "## Encoder(인코더)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb269f",
   "metadata": {},
   "source": [
    "### Multi-head Self Attention\n",
    "- Q(쿼리): '던져주는 값', 검색어\n",
    "- K(키) : 쿼리의 값을 기준으로 찾는 대상\n",
    "- V(값, 밸류): K가 갖고 있는 실제 값.\n",
    "- Q와 가장 관련이 깊은 K의 V위주로 모든 값을 가져오는 것이 Attention이다.\n",
    "\n",
    "<span style=\"color:blue\">Multi-head Self Attention의 장점</span><br>\n",
    "    - 교차검증처럼 하나를 쪼개어 여러가지로 결과를 도출 한 뒤, concat으로 연결해 정확도를 높인다.\n",
    "    - Attention head별로 다양한 task를 수행할 수 있도록 학습."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a00ab9",
   "metadata": {},
   "source": [
    "#### Q와 K와 V는 어떻게 만들어지는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb901ee8",
   "metadata": {},
   "source": [
    "- 입력받은 시퀀스를 3개로 copy한다.\n",
    "- copy한 각 시퀀스에 가중치 매트릭스(Q,K,V)를 곱해 산출한다.\n",
    "- Q에 K를 곱해 Attetion을 만들어낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01c1a5",
   "metadata": {},
   "source": [
    "- 소프트맥스 함수를 적용해, 각 토큰이 다른 토큰들과 갖는 관계적인 의미를 표현한다(가중치)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7225a281",
   "metadata": {},
   "source": [
    "#### mask(masking)이란 무엇인가?\n",
    "- Q x K 를 했을 때 필요없는 값(종결토큰)에는 0이 입력되므로 그것에 가중치(K)를 곱해 계산하면 전체 값이 이상해지므로, 종결토큰에 들어가는 0을 제외해주어야 한다.\n",
    "- 이러한 종결토큰의 0을 제외시켜주는 것을 mask 또는 masking이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e0fb67",
   "metadata": {},
   "source": [
    "## Decoder(디코더)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e50ef",
   "metadata": {},
   "source": [
    "- Encoder와 비슷한 흐름으로 과정이 흘러간다.\n",
    "- Encoder의 결과산출물이 Decoder에 들어가서 최종결과물이 완성되는 형태로 진행이 된다.\n",
    "<인코더의 최종결과물이 Decoder의 Multi-Head Attention에 이용됨>\n",
    "- 다만 Decoder의 mask 과정이 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7aa602",
   "metadata": {},
   "source": [
    "### mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847d8f7",
   "metadata": {},
   "source": [
    "- Padding token의 위치에 대한 masking\n",
    "- Attention 가중치를 구할 때 대상 토큰의 이후 시점의 토큰은 참조하지 못하도록 masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8dc5b3",
   "metadata": {},
   "source": [
    "## Linear & Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ee9c4",
   "metadata": {},
   "source": [
    "- Decoder 과정에서 도출된 결과물에 Linear과 Softmax를 이용해 최종결과물을 도출한다.\n",
    "- 실제 레이블과 cross entropy를 계산하여 loss 산출 및 학습<손실값 계산 및 학습>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e16968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
